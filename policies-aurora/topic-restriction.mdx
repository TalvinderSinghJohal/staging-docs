---
title: Topic Restrictions
description: "Ensures that AI interactions remain focused on approved subjects, preventing discussions outside defined boundaries."
---

## Overview

This policy safeguards the scope of AI interactions by restricting discussions to predefined valid topics and preventing engagement with specified invalid topics. The policy applies to both user inputs and AI-generated responses, ensuring that all interactions remain within approved subject areas. It works by monitoring and enforcing restrictions on topic boundaries, helping maintain focus and compliance with organizational requirements.

The **Restrict to Topic Policy** empowers organisations to control the types of topics that can be discussed during interactions with a Language Model (LLM). By defining a set of **Valid Topics** (permitted content) and **Invalid Topics** (restricted content), organisations can align AI usage with business objectives, regulatory standards, and ethical practices. This policy helps ensure that AI-generated conversations stay relevant, secure, and compliant.

---

## What the Policy Does

### Purpose

The primary goal of the Restrict to Topic Policy is to maintain content integrity by allowing only approved topics in AI interactions. Whether used to prevent off-topic discussions or to enforce strict content regulations, this policy enables organisations to:

- Maintain operational and ethical standards.
- Limit the AI to approved business functions.
- Prevent misuse or inappropriate use of the model.
- Ensure compliance with internal and industry regulations.

### Scope

#### Configurable Topic Control

Organisations can manage the AI’s scope of conversation using:

- **Valid Topics**: Topics that are explicitly allowed. These ensure that interactions remain business-focused and on-task.
- **Invalid Topics**: Topics that are explicitly disallowed. These help prevent discussions that may be sensitive, non-compliant, or irrelevant.

#### Prompt & Response Configuration

The policy can be applied independently to user **prompts (inputs)** and LLM **responses (outputs)**:

- Enable topic filtering on prompts, responses, or both.
- Apply unique settings for prompts and responses depending on the business context.

#### Operational Modes

- **Log Only**: The system flags and logs non-compliant prompts or responses without blocking them.
- **Log and Override**: Prompts or responses containing restricted topics are blocked entirely, ensuring that inappropriate content is not transmitted or displayed.

#### Threshold Sensitivity

A detection sensitivity threshold (range: **0.2 to 0.9**) allows fine-tuning of the model’s topic recognition:

- **Lower thresholds** (e.g., 0.2) are more lenient, reducing false positives.
- **Higher thresholds** (e.g., 0.9) are stricter, capturing more subtle or indirect topic violations.

### Key Features

- **Topic-Based Filtering**: Use allow-lists or block-lists to govern content scope.
- **Prompt & Response Independence**: Configure controls independently for each direction of interaction.
- **Flexible Enforcement Options**: Choose between monitoring and full blocking.
- **Customisable Detection Sensitivity**: Adjust how strictly the AI enforces topic restrictions.
- **Complete Logging**: All violations are logged for review, analysis, and compliance reporting.

---

## Why Use This Policy?

### Benefits

- Maintains focus on approved business topics.
- Reduces reputational and regulatory risk.
- Prevents sensitive, speculative, or irrelevant discussions.
- Enables automated, scalable topic governance.

---

## Use Case: Financial Services Governance

### Scenario

A global financial services firm uses an LLM-powered assistant internally to generate marketing copy, product comparisons, and training material. The company wants to ensure that content does not reference competitors like Company X, Y, or Z unless authorised.

### Challenge

Employees might unintentionally prompt the AI to mention competitor names or generate content that includes comparisons or references to rival platforms, breaching brand guidelines or legal constraints.

### Solution: Implementing the Restrict to Topic Policy

1. **Topic Configuration**  
   - **Valid Topics**: Risk analysis, financial compliance, economic forecasting.  
   - **Invalid Topics**: Client-specific discussions, investment predictions, non-business content.

2. **Prompt & Response Filtering**  
   - **Prompt Filtering**: Prevents employees from querying the AI about restricted subjects.  
   - **Response Filtering**: Stops the LLM from generating answers that violate company policy.

3. **Enforcement Mode & Sensitivity**  
   - Mode set to **Log and Override** for complete control.  
   - Sensitivity configured at **0.8** to ensure high accuracy in detecting restricted content.

---

## How to Use the Policy

> **Note:** The steps below guide you through configuring the Topic Restriction Policy using the policy workflow interface.

### Step 1: Navigate to the Policy Workflow

1. From the **Dashboard**, open the **Project Overview** by selecting your project from the **Project Table**.
2. In the **Policy** section of the Project Overview, click **Edit Policy** to launch the policy configuration workflow.

---

### Step 2: Select and Enable the Topic Restriction Policy

1. In the **Configure Policies** tab, a list of available policies will be displayed.
2. Click on **Topic Restriction** to open its configuration options on the right-hand side of the screen.
3. Toggle the **Enable Policy** switch to **ON** to begin configuration.

---

### Step 3: Define Valid and/or Invalid Topics

1. Under the **Topic Configuration** section, you’ll find two input fields:
   - **Valid Topics** – Enter allowed topics here. Press `Enter` after each topic to add it. These will appear as tags below the input field.
   - **Invalid Topics** – Enter restricted topics here. Press `Enter` after each entry. These will also display as tags.
2. You may configure **only Valid**, **only Invalid**, or **both**, depending on your organisation's requirements.
3. Topics can be removed by clicking the “X” on any tag.

---

### Step 4: Set Application Scope

1. Under **Apply Policy To**, choose where the policy will be enforced:
   - **Prompt** – User input only
   - **Response** – AI-generated output only
   - **Both** – Enforce on both directions

---

### Step 5: Configure Enforcement Behaviour

1. Under **Behaviour**, choose how the system should respond to restricted topics:
   - **Log Only** – Flag violations without blocking the interaction.
   - **Log and Override** – Block the prompt or response and return a smart message based on your response configuration.

---

### Step 6: Adjust Detection Threshold

1. Use the **Threshold Slider** to set how strictly topics should be matched:
   - Lower values (e.g., `0.2`) allow broader interpretation and fewer false positives.
   - Higher values (e.g., `0.9`) enforce stricter topic detection and filtering.
2. The selected threshold level will be displayed numerically alongside the slider.

---

### Step 7: Save, Test, and Apply the Policy

1. Click **Save Changes** to store your configuration settings.
2. *(Optional)* Navigate to the **Test Policies** tab to simulate prompts and validate policy enforcement live.
3. Return to the **Configure Policies** tab and click **Apply Policies** to activate the configuration.
4. A success message will confirm the policy has been applied to your project.

---

The **Topic Restriction Policy** provides full control over allowable and prohibited discussion topics—ensuring your AI interactions remain relevant, compliant, and aligned with your organisation's standards.
