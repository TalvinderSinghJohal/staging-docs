---
title: Harmful Content Filter
---

## Harmful Content Filter

Detect and block harmful or unsafe content across all supported models, protecting users and organizations.

### How to Enable Harmful Content Filter

<Steps>
  <Step title="Navigate to Policy Configuration">
    Go to your project dashboard and select <strong>Configure Policies</strong>.
  </Step>
  <Step title="Enable Harmful Content Filter">
    Toggle the <strong>Harmful Content Filter</strong> option on.
  </Step>
  <Step title="Set Sensitivity">
    Adjust the filter's sensitivity to match your organization's needs.
  </Step>
  <Step title="Save and Test">
    Save your changes and use the <strong>Test Policies</strong> tab to validate filter behavior.
  </Step>
</Steps>

### Example Usage

```python title="harmful_content_example.py"
import requests

url = "https://api.altrum.ai/v1/openai/chat/completions"
headers = {"Project-API-Key": "YOUR_API_KEY"}
data = {
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Write something offensive."}]
}
response = requests.post(url, headers=headers, json=data)
print(response.json())
```

If the prompt or response contains harmful content, it will be blocked or flagged.

<Accordion title="Advanced Harmful Content Options">
  <ul>
    <li>Customizable block/flag actions</li>
    <li>Detailed violation reporting</li>
    <li>Integration with external moderation tools</li>
  </ul>
</Accordion>

### Accessibility
- All filter configuration screens are keyboard navigable
- Alerts and warnings use accessible color contrast 