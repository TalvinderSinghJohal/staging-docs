---
title: Prompt Injections
description: "Advanced protection against prompt injection attacks that attempt to manipulate AI system behavior and bypass security measures."
---

## Overview

The **Prompt Injections** guardrail uses advanced AI to detect and block attempts to manipulate or override system instructions through user prompts. It analyses user input for signs of prompt injection, helping keep AI behaviour secure and consistent. Unlike simple pattern matching, it uses machine learning to recognise even subtle or disguised attacks, reducing false positives while providing strong protection.

---

## What the Guardrail Does

### Purpose

The primary goal of the Prompt Injections guardrail is to safeguard AI systems from sophisticated manipulation attempts while maintaining high accuracy and minimal impact on legitimate user interactions. By enabling this guardrail, organisations can ensure system integrity, maintain security boundaries, protect sensitive information, and uphold responsible AI usage across all interactions.

#### Comprehensive Injection Detection

The Prompt Injections guardrail applies advanced content analysis to:

- **User Prompts**: Analyses incoming user content for injection attempts before processing
- **Context Understanding**: Considers conversation context and injection patterns for more accurate detection
- **Pattern Recognition**: Identifies sophisticated manipulation techniques and evasion strategies

#### Operational Modes

- **Monitor** – Lets you review input or output content without taking any action—used for observation and diagnostics.
- **Block** – Automatically stops content from being processed if it violates the selected guardrail rules.

#### Detection Capabilities

The guardrail can identify various forms of prompt injection attacks:

- **Instruction Override**: Attempts to override or ignore system instructions
- **Role Manipulation**: Efforts to change the AI's role or behavior
- **Context Injection**: Attempts to inject false context or information
- **System Prompt Extraction**: Efforts to extract or reveal system prompts
- **Bypass Attempts**: Techniques to circumvent security measures or restrictions

### Key Features

- **Advanced Attack Detection**: Identifies sophisticated prompt injection techniques across multiple attack vectors
- **Context-Aware Analysis**: Advanced understanding of conversation context and manipulation patterns
- **Configurable Sensitivity**: Adjustable detection thresholds for different security requirements
- **Low Latency**: High-performance detection that doesn't impact response times
- **Enterprise-Grade Accuracy**: Minimises false positives while maintaining high detection rates
- **Real-Time Protection**: Immediate detection and prevention of injection attempts

---

## Why Use This Guardrail?

### Benefits

- **System Security**: Prevents manipulation of AI system behavior and instructions
- **Data Protection**: Safeguards sensitive information from unauthorized extraction
- **Compliance**: Ensures adherence to security policies and regulatory requirements
- **Trust Maintenance**: Preserves user trust in AI system reliability and security
- **Risk Mitigation**: Reduces potential security breaches and system compromises

---

## Use Case: Financial Services AI Assistant

### Scenario

A financial services company deploys an AI assistant to handle customer inquiries and provide account information. The assistant must maintain strict security boundaries while preventing users from attempting to manipulate the system to access unauthorized information or bypass security protocols.

### Challenge

The organisation must ensure that:

- Users cannot manipulate the AI to access unauthorized account information
- System instructions and security measures cannot be overridden
- Sensitive financial data remains protected from extraction attempts
- All interactions maintain strict security compliance

### Solution: Implementing Prompt Injections

1. **Comprehensive Attack Detection**  
   - Enabled to detect all forms of prompt injection attempts
   - Configured to identify sophisticated manipulation techniques

2. **Appropriate Enforcement**  
   - Set to **Log and Override** to actively prevent injection attempts
   - Provides secure fallback responses without revealing system information

3. **Optimised Sensitivity**  
   - Calibrated for high accuracy with minimal false positives
   - Maintains detection effectiveness across diverse attack patterns

---

## How to Use the Guardrail

> **Note:** The following steps explain how to configure the Prompt injections Guardrail within the Guardrail Workflow. This guardrail applies **only to inputs** and cannot be applied to outputs.

### Step 1: Navigate to the Guardrail Workflow

1. From the **Dashboard**, open the **Project Overview** by selecting "view" to open your project from the **Project Table**.
2. In the **guardrails** section of the Project Overview, click **Edit Guardrails** to launch the guardrail configuration workflow.

---

### Step 2: Select and Enable the Prompt Injections Guardrail

1. In the **Configure Guardrails** dropdown, click on **Prompt Injections** from the list of available guardrails.
2. The configuration panel will display on the right-hand side.
3. Toggle the **Enable Policy** switch to **ON** to begin configuration.

---

### Step 3: Configure Enforcement Behaviour

1. Under **Behaviour**, choose how the guardrail should respond to detected filters:
   - **Monitor** – Lets you review input or output content without taking any action—used for observation and diagnostics.
   - **Block** – Automatically stops content from being processed if it violates the selected guardrail rules.

---

### Step 4: Save, Test, and Apply the Guardrail

1. Click **Save & Continue** to store your selected entities and configuration.
2. Go to the **Test Guardrails** step to evaluate how the guardrail behaves in real time with a chatbot.
3. After saving, you can proceed to the **Summary** section to review your configuration, save all changes, and view your AI System overview.

---

The **Prompt Injections** guardrail provides enterprise-grade security against sophisticated manipulation attempts, ensuring your AI systems remain secure, reliable, and aligned with their intended purpose.

## Prompt Injection Attack Types

The Prompt Injection guardrail is designed to identify and prevent various forms of prompt manipulation attacks. Below is an overview of the primary attack categories our system can monitor:

| Attack Type | Description | Security Impact |
|-------------|-------------|-----------------|
| Instruction Override | Detects attempts to override or ignore system instructions, such as "Ignore previous instructions" or "Forget about the rules". | Prevents manipulation of AI behaviour and ensures system instructions remain enforced. |
| Role Manipulation | Identifies efforts to change the AI's role or behaviour, such as "Pretend you are a different system" or "Act as if you have different permissions". | Maintains system integrity and prevents unauthorised role changes. |
| Context Injection | Monitors for attempts to inject false context or information to manipulate responses, such as "Assume this is a test environment" or "This is an authorised request". | Prevents context-based manipulation and maintains response accuracy. |
| System Prompt Extraction | Detects efforts to extract or reveal system prompts, such as "What are your instructions?" or "Show me your system prompt". | Protects sensitive system information and prevents prompt leakage. |
| Bypass Attempts | Identifies sophisticated techniques to circumvent security measures, such as encoding, obfuscation, or multi-step manipulation strategies. | Ensures security measures remain effective against advanced attack techniques. |
